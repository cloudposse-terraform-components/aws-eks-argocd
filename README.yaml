name: "aws-eks-argocd"
# Canonical GitHub repo
github_repo: "cloudposse-terraform-components/aws-eks-argocd"
# Short description of this project
description: |-
  This component provisions [Argo CD](https://argoproj.github.io/cd/), a declarative GitOps continuous delivery tool for Kubernetes.

  Note: Argo CD CRDs must be installed separately from this component/Helm release.
usage: |-
  ### Install Argo CD CRDs

  Install the Argo CD CRDs prior to deploying this component:

  ```shell
  kubectl apply -k "https://github.com/argoproj/argo-cd/manifests/crds?ref=<appVersion>"

  # Eg. version v2.4.9
  kubectl apply -k "https://github.com/argoproj/argo-cd/manifests/crds?ref=v2.4.9"
  ```

  ### Preparing AppProject repos

  First, make sure you have a GitHub repo ready to go. We have a component for this called the `argocd-repo` component. It
  will create a GitHub repo and adds some secrets and code owners. Most importantly, it configures an
  `applicationset.yaml` that includes all the details for helm to create ArgoCD CRDs. These CRDs let ArgoCD know how to
  fulfill changes to its repo.

  ```yaml
  components:
    terraform:
      argocd-repo-defaults:
        metadata:
          type: abstract
        vars:
          enabled: true
          github_user: acme_admin
          github_user_email: infra@acme.com
          github_organization: ACME
          github_codeowner_teams:
            - "@ACME/acme-admins"
            - "@ACME/CloudPosse"
            - "@ACME/developers"
          gitignore_entries:
            - "**/.DS_Store"
            - ".DS_Store"
            - "**/.vscode"
            - "./vscode"
            - ".idea/"
            - ".vscode/"
          permissions:
            - team_slug: acme-admins
              permission: admin
            - team_slug: CloudPosse
              permission: admin
            - team_slug: developers
              permission: push
  ```

  ### Injecting infrastructure details into applications

  Second, your application repos could use values to best configure their helm releases. We have an `eks/platform`
  component for exposing various infra outputs. It takes remote state lookups and stores them into SSM. We demonstrate how
  to pull the platform SSM parameters later. Here's an example `eks/platform` config:

  ```yaml
  components:
    terraform:
      eks/platform:
        metadata:
          type: abstract
          component: eks/platform
        backend:
          s3:
            workspace_key_prefix: platform
        deps:
          - catalog/eks/cluster
          - catalog/eks/alb-controller-ingress-group
          - catalog/acm
        vars:
          enabled: true
          name: "platform"
          eks_component_name: eks/cluster
          ssm_platform_path: /platform/%s/%s
          references:
            default_alb_ingress_group:
              component: eks/alb-controller-ingress-group
              output: .group_name
            default_ingress_domain:
              component: dns-delegated
              environment: gbl
              output: "[.zones[].name][-1]"

      eks/platform/acm:
        metadata:
          component: eks/platform
          inherits:
            - eks/platform
        vars:
          eks_component_name: eks/cluster
          references:
            default_ingress_domain:
              component: acm
              environment: use2
              output: .domain_name

      eks/platform/dev:
        metadata:
          component: eks/platform
          inherits:
            - eks/platform
        vars:
          platform_environment: dev

      acm/qa2:
        settings:
          spacelift:
            workspace_enabled: true
        metadata:
          component: acm
        vars:
          enabled: true
          name: acm-qa2
          tags:
            Team: sre
            Service: acm
          process_domain_validation_options: true
          validation_method: DNS
          dns_private_zone_enabled: false
          certificate_authority_enabled: false
  ```

  In the previous sample we create platform settings for a `dev` platform and a `qa2` platform. Understand that these are
  arbitrary titles that are used to separate the SSM parameters so that if, say, a particular hostname is needed, we can
  safely select the right hostname using a moniker such as `qa2`. These otherwise are meaningless and do not need to align
  with any particular stage or tenant.

  ### ArgoCD on SAML / AWS Identity Center (formerly aws-sso)

  Here's an example snippet for how to use this component:

  ```yaml
  components:
    terraform:
      eks/argocd:
        settings:
          spacelift:
            workspace_enabled: true
            depends_on:
              - argocd-applicationset
              - tenant-gbl-corp-argocd-depoy-non-prod
        vars:
          enabled: true
          alb_group_name: argocd
          alb_name: argocd
          alb_logs_prefix: argocd
          certificate_issuer: selfsigning-issuer
          github_organization: MyOrg
          oidc_enabled: false
          saml_enabled: true
          ssm_store_account: corp
          ssm_store_account_region: us-west-2
          argocd_repo_name: argocd-deploy-non-prod
          argocd_rbac_policies:
            - "p, role:org-admin, applications, *, */*, allow"
            - "p, role:org-admin, clusters, get, *, allow"
            - "p, role:org-admin, repositories, get, *, allow"
            - "p, role:org-admin, repositories, create, *, allow"
            - "p, role:org-admin, repositories, update, *, allow"
            - "p, role:org-admin, repositories, delete, *, allow"
          # Note: the IDs for AWS Identity Center groups will change if you alter/replace them:
          argocd_rbac_groups:
            - group: deadbeef-dead-beef-dead-beefdeadbeef
              role: admin
            - group: badca7sb-add0-65ba-dca7-sbadd065badc
              role: reader
          chart_values:
            global:
              logging:
                format: json
                level: warn

      sso-saml/aws-sso:
        settings:
          spacelift:
            workspace_enabled: true
        metadata:
          component: sso-saml-provider
        vars:
          enabled: true
          ssm_path_prefix: "/sso/saml/aws-sso"
          usernameAttr: email
          emailAttr: email
          groupsAttr: groups
  ```

  Note, if you set up `sso-saml-provider`, you will need to restart DEX on your EKS cluster manually:

  ```bash
  kubectl delete pod <dex-pod-name> -n argocd
  ```

  The configuration above will work for AWS Identity Center if you have the following attributes in a
  [Custom SAML 2.0 application](https://docs.aws.amazon.com/singlesignon/latest/userguide/samlapps.html):

  | attribute name | value           | type        |
  | :------------- | :-------------- | :---------- |
  | Subject        | ${user:subject} | persistent  |
  | email          | ${user:email}   | unspecified |
  | groups         | ${user:groups}  | unspecified |

  You will also need to assign AWS Identity Center groups to your Custom SAML 2.0 application. Make a note of each group
  and replace the IDs in the `argocd_rbac_groups` var accordingly.

  ### Google Workspace OIDC

  To use Google OIDC:

  ```yaml
  oidc_enabled: true
  saml_enabled: false
  oidc_providers:
    google:
      uses_dex: true
      type: google
      id: google
      name: Google
      serviceAccountAccess:
        enabled: true
        key: googleAuth.json
        value: /sso/oidc/google/serviceaccount
        admin_email: an_actual_user@acme.com
      config:
        # This filters emails when signing in with Google to only this domain. helpful for picking the right one.
        hostedDomains:
          - acme.com
        clientID: /sso/saml/google/clientid
        clientSecret: /sso/saml/google/clientsecret
  ```

  ### Working with ArgoCD and GitHub

  Here's a simple GitHub action that will trigger a deployment in ArgoCD:

  ```yaml
  # NOTE: Example will show dev, and qa2
  name: argocd-deploy
  on:
    push:
      branches:
        - main
  jobs:
    ci:
      runs-on: ubuntu-latest
      steps:
        - name: Checkout
          uses: actions/checkout@v3
        - name: Configure AWS Credentials
          uses: aws-actions/configure-aws-credentials@v2.1.0
          with:
            aws-region: us-east-2
            role-to-assume: arn:aws:iam::123456789012:role/github-action-worker
        - name: Build
          shell: bash
          run: docker build -t some.docker.repo/acme/app . & docker push some.docker.repo/acmo/app
        - name: Checkout Argo Configuration
          uses: actions/checkout@v3
          with:
            repository: acme/argocd-deploy-non-prod
            ref: main
            path: argocd-deploy-non-prod
        - name: Deploy to dev
          shell: bash
          run: |
            echo Rendering helmfile:
            helmfile \
              --namespace acme-app \
              --environment dev \
              --file deploy/app/release.yaml \
              --state-values-file <(aws ssm get-parameter --name /platform/dev),<(docker image inspect some.docker.repo/acme/app) \
              template > argocd-deploy-non-prod/plat/use2-dev/apps/my-preview-acme-app/manifests/resources.yaml
            echo Updating sha for app:
            yq e '' -i argocd-deploy-non-prod/plat/use2-dev/apps/my-preview-acme-app/config.yaml
            echo Committing new helmfile
            pushd argocd-deploy-non-prod
            git add --all
            git commit --message 'Updating acme-app'
            git push
            popd
  ```

  In the above example, we make a few assumptions:

  - You've already made the app in ArgoCD by creating a YAML file in your non-prod ArgoCD repo at the path
    `plat/use2-dev/apps/my-preview-acme-app/config.yaml` with contents:

  ```yaml
  app_repository: acme/app
  app_commit: deadbeefdeadbeef
  app_hostname: https://some.app.endpoint/landing_page
  name: my-feature-branch.acme-app
  namespace: my-feature-branch
  manifests: plat/use2-dev/apps/my-preview-acme-app/manifests
  ```

  - you have set up `ecr` with permissions for github to push docker images to it
  - you already have your `ApplicationSet` and `AppProject` crd's in `plat/use2-dev/argocd/applicationset.yaml`, which
    should be generated by our `argocd-repo` component.
  - your app has a [helmfile template](https://helmfile.readthedocs.io/en/latest/#templating) in `deploy/app/release.yaml`
  - that helmfile template can accept both the `eks/platform` config which is pulled from ssm at the path configured in
    `eks/platform/defaults`
  - the helmfile template can update container resources using the output of `docker image inspect`

  ### Notifications

  Here's a configuration for letting argocd send notifications back to GitHub:

  1. [Create GitHub PAT](https://docs.github.com/en/enterprise-server@3.6/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens#creating-a-personal-access-token)
    with scope `repo:status`
  2. Save the PAT to SSM `/argocd/notifications/notifiers/common/github-token`
  3. Use this atmos stack configuration

  ```yaml
  components:
    terraform:
      eks/argocd/notifications:
        metadata:
          component: eks/argocd
        vars:
          github_default_notifications_enabled: true
  ```

  ### Webhook

  Here's a configuration Github notify ArgoCD on commit:

  1. [Create GitHub PAT](https://docs.github.com/en/enterprise-server@3.6/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens#creating-a-personal-access-token)
    with scope `admin:repo_hook`
  2. Save the PAT to SSM `/argocd/github/api_key`
  3. Use this atmos stack configuration

  ```yaml
  components:
    terraform:
      eks/argocd/notifications:
        metadata:
          component: eks/argocd
        vars:
          github_webhook_enabled: true
  ```

  #### Creating Webhooks with `github-webhook`

  If you are creating webhooks for ArgoCD deployment repos in multiple GitHub Organizations, you cannot use the same
  Terraform GitHub provider. Instead, we can use Atmos to deploy multiple component. To do this, disable the webhook
  creation in this component and deploy the webhook with the `github-webhook` component as such:

  ```yaml
  components:
    terraform:
      eks/argocd:
        metadata:
          component: eks/argocd
          inherits:
            - eks/argocd/defaults
        vars:
          github_webhook_enabled: true # create webhook value; required for argo-cd chart
          create_github_webhook: false # created with github-webhook
          argocd_repositories:
            "argocd-deploy-non-prod/org1": # this is the name of the `argocd-repo` component for "org1"
              environment: ue2
              stage: auto
              tenant: core
            "argocd-deploy-non-prod/org2":
              environment: ue2
              stage: auto
              tenant: core

      webhook/org1/argocd:
        metadata:
          component: github-webhook
        vars:
          github_organization: org1
          github_repository: argocd-deploy-non-prod
          webhook_url: "https://argocd.ue2.dev.plat.acme.org/api/webhook"
          ssm_github_webhook: "/argocd/github/webhook"

      webhook/org2/argocd:
        metadata:
          component: github-webhook
        vars:
          github_organization: org2
          github_repository: argocd-deploy-non-prod
          webhook_url: "https://argocd.ue2.dev.plat.acme.org/api/webhook"
          ssm_github_webhook: "/argocd/github/webhook"
  ```

  ### Slack Notifications

  ArgoCD supports Slack notifications on application deployments.

  1. In order to enable Slack notifications, first create a Slack Application following the
    [ArgoCD documentation](https://argocd-notifications.readthedocs.io/en/stable/services/slack/).
  1. Create an OAuth token for the new Slack App
  1. Save the OAuth token to AWS SSM Parameter Store in the same account and region as Github tokens. For example,
    `core-use2-auto`
  1. Add the app to the chosen Slack channel. _If not added, notifications will not work_
  1. For this component, enable Slack integrations for each Application with `var.slack_notifications_enabled` and
    `var.slack_notifications`:

  ```yaml
  slack_notifications_enabled: true
  slack_notifications:
    channel: argocd-updates
  ```

  6. In the `argocd-repo` component, set `var.slack_notifications_channel` to the name of the Slack notification channel
    to add the relevant ApplicationSet annotations

  ### Troubleshooting

  #### Login to ArgoCD admin UI

  For ArgoCD v1.9 and later, the initial admin password is available from a Kubernetes secret named
  `argocd-initial-admin-secret`. To get the initial password, execute the following command:

  ```shell
  kubectl get secret -n argocd argocd-initial-admin-secret -o jsonpath='{.data.password}' | base64 --decode
  ```

  Then open the ArgoCD admin UI and use the username `admin` and the password obtained in the previous step to log in to
  the ArgoCD admin.

  #### Error "server.secretkey is missing"

  If you provision a new version of the `eks/argocd` component, and some Helm Chart values get updated, you might
  encounter the error "server.secretkey is missing" in the ArgoCD admin UI. To fix the error, execute the following
  commands:

  ```shell
  # Download `kubeconfig` and set EKS cluster
  set-eks-cluster cluster-name

  # Restart the `argocd-server` Pods
  kubectl rollout restart deploy/argocd-server -n argocd

  # Get the new admin password from the Kubernetes secret
  kubectl get secret -n argocd argocd-initial-admin-secret -o jsonpath='{.data.password}' | base64 --decode
  ```

  Reference: https://stackoverflow.com/questions/75046330/argo-cd-error-server-secretkey-is-missing

  <!-- prettier-ignore-start -->
  <!-- prettier-ignore-end -->
references:
  - name: Argo CD
    description: ""
    url: https://argoproj.github.io/cd/
  - name: Argo CD Docs
    description: ""
    url: https://argo-cd.readthedocs.io/en/stable/
  - name: Argo Helm Chart
    description: ""
    url: https://github.com/argoproj/argo-helm/blob/master/charts/argo-cd/
  - name: Argo CD error "server.secretkey is missing"
    description: ""
    url: https://stackoverflow.com/questions/75046330/argo-cd-error-server-secretkey-is-missing
tags:
  - component/eks/argocd
  - layer/software-delivery
  - provider/aws
  - provider/helm
# Categories of this project
categories:
  - component/eks/argocd
  - layer/software-delivery
  - provider/aws
  - provider/helm
# License of this project
license: "APACHE2"
# Badges to display
badges:
  - name: Latest Release
    image: https://img.shields.io/github/release/cloudposse-terraform-components/aws-eks-argocd.svg?style=for-the-badge
    url: https://github.com/cloudposse-terraform-components/aws-eks-argocd/releases/latest
  - name: Slack Community
    image: https://slack.cloudposse.com/for-the-badge.svg
    url: https://slack.cloudposse.com
related:
  - name: "Cloud Posse Terraform Modules"
    description: Our collection of reusable Terraform modules used by our reference architectures.
    url: "https://docs.cloudposse.com/modules/"
  - name: "Atmos"
    description: "Atmos is like docker-compose but for your infrastructure"
    url: "https://atmos.tools"
contributors: [] # If included generates contribs
